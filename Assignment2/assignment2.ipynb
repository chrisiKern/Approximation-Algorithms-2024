{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMuSlKg2FrhS"
   },
   "source": [
    "# Approximation Algorithms - Assignment 2\n",
    "### Group 2: Christoph Kern, Johannes Gabriel Sindlinger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIlfse0aFxF-"
   },
   "source": [
    "Install the hyperloglog library and read data files"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lKB_dxn_S8LQ",
    "ExecuteTime": {
     "end_time": "2024-04-30T14:52:41.727153Z",
     "start_time": "2024-04-30T14:52:40.298688Z"
    }
   },
   "source": [
    "!curl https://raw.githubusercontent.com/rasmus-pagh/apx/main/data/words_danish.txt -o words_danish.txt\n",
    "!curl https://raw.githubusercontent.com/rasmus-pagh/apx/main/data/words_english.txt -o words_english.txt\n",
    "\n",
    "import hyperloglog\n",
    "import copy"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  258k  100  258k    0     0   850k      0 --:--:-- --:--:-- --:--:--  851k\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100 4135k  100 4135k    0     0  4927k      0 --:--:-- --:--:-- --:--:-- 4923k\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgXunJliF5SI"
   },
   "source": [
    "The code below reads two lists of words from files and prints statistics using a hyperloglog sketch"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ONEGRAPAFNx",
    "outputId": "d9dd9ca7-fb89-432f-ab80-932225f90558",
    "ExecuteTime": {
     "end_time": "2024-04-30T14:59:20.345919Z",
     "start_time": "2024-04-30T14:58:55.030360Z"
    }
   },
   "source": [
    "def create_hll(filename, relative_error):\n",
    "  hll = hyperloglog.HyperLogLog(relative_error)\n",
    "  with open(filename, 'r') as f:\n",
    "    for word in f:\n",
    "      hll.add(word)\n",
    "  return hll\n",
    "\n",
    "relative_error = 0.01\n",
    "hll_danish = create_hll('words_danish.txt', relative_error)\n",
    "hll_english = create_hll('words_english.txt', relative_error)\n",
    "\n",
    "print(f'HLL reports about {len(hll_danish)} Danish words and {len(hll_english)} English words')\n",
    "\n",
    "hll_combined = copy.deepcopy(hll_english) # Create a copy of the HLL\n",
    "hll_combined.update(hll_danish) # Merge the other HLL into the combined one\n",
    "print(f'Combined the two languages have about {len(hll_combined)} words')"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HLL reports about 414464 Danish words and 3928867 English words\n",
      "Combined the two languages have about 4292008 words\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ul5g6jCfKIUt"
   },
   "source": [
    "## Task:\n",
    "\n",
    "Your task is to add code, or modify the code, to compute information about the number of distinct substrings in the two languages. For example, the word \"pop\" has 6 distinct substrings, namely \"\" (the empty string), \"p\", \"o\", \"po\", \"op\" and \"pop\". Note that \"pp\" is not a substring since the letters are not consecutive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9SCKevnKywl"
   },
   "source": [
    "\n",
    "1. Use a hyperloglog data structure with relative error 0.01 to compute upper and lower bounds on the number of distinct substrings in Danish and English, respectively. You may assume that HLL is guaranteed to return a number with the stated relative error."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414464 Danish substrings [410319.36, 418608.64]\n",
      "3928867 English substrings [3889578.33, 3968155.67]\n"
     ]
    }
   ],
   "source": [
    "def create_hll_substrings(filename, relative_error):\n",
    "  hll = hyperloglog.HyperLogLog(relative_error)\n",
    "  with open(filename, 'r') as f:\n",
    "    for word in f:\n",
    "        n = len(word)\n",
    "        hll.add(\"\")\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n + 1):\n",
    "                hll.add(word[i:j])\n",
    "  return hll\n",
    "\n",
    "relative_error = 0.01\n",
    "\n",
    "hll_danish_substrings = create_hll_substrings('words_danish.txt', relative_error)\n",
    "hll_danish_substrings_estimate = len(hll_danish_substrings)\n",
    "hll_danish_substrings_lower_bound = hll_danish_substrings_estimate * (1 - relative_error)\n",
    "hll_danish_substrings_upper_bound = hll_danish_substrings_estimate * (1 + relative_error)\n",
    "print(f'{hll_danish_substrings_estimate} Danish substrings [{hll_danish_substrings_lower_bound}, {hll_danish_substrings_upper_bound}]')\n",
    "\n",
    "hll_english_substrings = create_hll_substrings('words_english.txt', relative_error)\n",
    "hll_english_substrings_estimate = len(hll_english_substrings)\n",
    "hll_english_substrings_lower_bound = hll_english_substrings_estimate * (1 - relative_error)\n",
    "hll_english_substrings_upper_bound = hll_english_substrings_estimate * (1 + relative_error)\n",
    "print(f'{hll_english_substrings_estimate} English substrings [{hll_english_substrings_lower_bound}, {hll_english_substrings_upper_bound}]')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T17:30:55.288348Z",
     "start_time": "2024-04-30T17:30:29.917980Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Based on the answer from 1), and a cardinality estimate for the union, give upper and lower bounds on the number of common substrings in the two languages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4292008 combined substrings [4249087.92, 4334928.08]\n",
      "51323 common substrings [-35030.389999999665, 137676.38999999966]\n"
     ]
    }
   ],
   "source": [
    "hll_combined_substrings = copy.deepcopy(hll_english_substrings)\n",
    "hll_combined_substrings.update(hll_danish_substrings)\n",
    "hll_combined_substrings_estimate = len(hll_combined_substrings)\n",
    "hll_combined_substrings_lower_bound = hll_combined_substrings_estimate * (1 - relative_error)\n",
    "hll_combined_substrings_upper_bound = hll_combined_substrings_estimate * (1 + relative_error)\n",
    "print(f'{hll_combined_substrings_estimate} combined substrings [{hll_combined_substrings_lower_bound}, {hll_combined_substrings_upper_bound}]')\n",
    "\n",
    "hll_common_substrings_count = hll_danish_substrings_estimate + hll_english_substrings_estimate - hll_combined_substrings_estimate\n",
    "hll_common_substrings_lower_bound = hll_danish_substrings_lower_bound + hll_english_substrings_lower_bound - hll_combined_substrings_upper_bound\n",
    "hll_common_substrings_upper_bound = hll_danish_substrings_upper_bound + hll_english_substrings_upper_bound - hll_combined_substrings_lower_bound\n",
    "print(f'{hll_common_substrings_count} common substrings [{hll_common_substrings_lower_bound}, {hll_common_substrings_upper_bound}]')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T17:31:00.550509Z",
     "start_time": "2024-04-30T17:31:00.536294Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Suppose that the intersection size is at least 1% of each of the two sets. How small relative error on the cardinality estimates would you need to estimate the number of common substrings up to a relative error of 10%? (NB! The implementation provided does not support very small relative errors.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
